{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, yaml\n",
    "from datetime import datetime\n",
    "from easydict import EasyDict\n",
    "from glob import glob\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataloader.bci_compet import get_dataset\n",
    "from dataloader.bci_compet import BCICompet2aIV\n",
    "\n",
    "from model.litmodel import LitModel\n",
    "from model.litmodel import get_litmodel\n",
    "from model.cat_conditioned import CatConditioned\n",
    "from model.attn_conditioned import ATTNConditioned\n",
    "from model.attn_conditioned_subj_avg import ATTNConditionedSubjAvg\n",
    "from model.attn_conditioned_subj_ftr import ATTNConditionedSubjFtr\n",
    "\n",
    "\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set confings\n",
    "config_name = 'bcicompet2a_config'\n",
    "with open(f'configs/{config_name}.yaml') as file:\n",
    "    config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    args = EasyDict(config)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Set Device ####\n",
    "# if torch.cuda.is_available():\n",
    "#     os.environ['CUDA_VISIBLE_DEVICES'] = str(args.GPU_NUM)\n",
    "cudnn.benchmark = True\n",
    "cudnn.fastest = True\n",
    "cudnn.deterministic = True\n",
    "\n",
    "#### Set SEED ####\n",
    "seed_everything(args.SEED)\n",
    "\n",
    "#### Update configs ####\n",
    "if args.downsampling != 0: args['sampling_rate'] = args.downsampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_ROOT = 'cache'\n",
    "TEST_ROOT = 'test_results'\n",
    "\n",
    "args.is_test = True\n",
    "\n",
    "def load_dataset(args, return_subject_id=False):\n",
    "    datasets = {}\n",
    "    for subject_id in range(0,9):\n",
    "        args['target_subject'] = subject_id\n",
    "        datasets[subject_id] = BCICompet2aIV(args)\n",
    "    return datasets\n",
    "\n",
    "path = os.path.join(CACHE_ROOT, f'{config_name}_base_test.pkl')\n",
    "\n",
    "if not os.path.isfile(path):\n",
    "    print('Cache miss, generating cache')\n",
    "    datasets = load_dataset(args)\n",
    "    with open(path, 'wb') as file:\n",
    "        pickle.dump(datasets, file)\n",
    "else:\n",
    "    print('Loading cache')\n",
    "    with open(path, 'rb') as file:\n",
    "        datasets = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method =  'baseline'\n",
    "subj_info = ''\n",
    "\n",
    "\n",
    "trains = glob(f'{args.CKPT_PATH}/{args.task}/*{method}_L1SO_*')\n",
    "versions = [train.split(os.sep)[-1] for train in trains]\n",
    "print(versions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result_dict = {}\n",
    "for version in versions:\n",
    "    LOS = int(version.split('_')[-1])\n",
    "    ckpt_path = sorted(glob(f'{args.CKPT_PATH}/{args.task}/{version}/*.ckpt'))[-1]\n",
    "    print()\n",
    "    print(ckpt_path)\n",
    "    print(LOS)\n",
    "    print()\n",
    "\n",
    "    model = get_litmodel(args)\n",
    "    #in_model =  ATTNConditionedSubjAvg(args, embedding_dimension=44, combined_features_dimension=72 )\n",
    "    #in_model = ATTNConditionedSubjFtr(args, embedding_dimension=23, combined_features_dimension=43, subj_dim=26 )\n",
    "    #model = LitModel(args, in_model)\n",
    "    model.load_state_dict(torch.load(ckpt_path)['state_dict'], strict=False)\n",
    "    trainer = Trainer()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    datasets[LOS].return_subject_info = subj_info\n",
    "    test_dataloader = DataLoader(datasets[LOS],\n",
    "                                    batch_size=args.batch_size,\n",
    "                                    pin_memory=False,\n",
    "                                    num_workers=args.num_workers)\n",
    "    gt = datasets[LOS].label                                   \n",
    "    logits = trainer.predict(model, dataloaders=test_dataloader)\n",
    "    pred = torch.cat(logits, dim=0).argmax(axis=1).detach().cpu().numpy()\n",
    "    acc = accuracy_score(pred, gt)\n",
    "    kappa = cohen_kappa_score(pred, gt)\n",
    "    result_dict[LOS] = {'acc': acc, 'kappa': kappa}\n",
    "result_df = pd.DataFrame(result_dict).T\n",
    "os.mkdir(f'{TEST_ROOT}/{args.task}/{method}')\n",
    "result_df.to_csv(f'{TEST_ROOT}/{args.task}/{method}/{datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")}_L1SO.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
