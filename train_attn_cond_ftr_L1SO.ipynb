{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import os, yaml\n",
    "from easydict import EasyDict\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from dataloader.bci_compet import get_dataset\n",
    "from dataloader.bci_compet import BCICompet2aIV\n",
    "\n",
    "from model.litmodel import LitModel\n",
    "from model.attn_conditioned_subj_ftr import ATTNConditionedSubjFtr\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "\n",
    "\n",
    "from utils.setup_utils import (\n",
    "    get_device,\n",
    "    get_log_name,\n",
    ")\n",
    "from utils.training_utils import get_callbacks\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_ROOT = 'cache'\n",
    "\n",
    "config_name = 'bcicompet2a_config'\n",
    "\n",
    "with open(f'configs/{config_name}.yaml') as file:\n",
    "    config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    args = EasyDict(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cache\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(args, return_subject_id=False):\n",
    "    datasets = {}\n",
    "    for subject_id in range(0,9):\n",
    "        args['target_subject'] = subject_id\n",
    "        datasets[subject_id] = BCICompet2aIV(args)\n",
    "    return datasets\n",
    "\n",
    "path = os.path.join(CACHE_ROOT, f'{config_name}_base.pkl')\n",
    "\n",
    "if not os.path.isfile(path):\n",
    "    print('Cache miss, generating cache')\n",
    "    datasets = load_dataset(args)\n",
    "    with open(path, 'wb') as file:\n",
    "        pickle.dump(datasets, file)\n",
    "else:\n",
    "    print('Loading cache')\n",
    "    with open(path, 'rb') as file:\n",
    "        datasets = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 0 has 288 trials\n",
      "Subject 1 has 288 trials\n",
      "Subject 2 has 288 trials\n",
      "Subject 3 has 288 trials\n",
      "Subject 4 has 288 trials\n",
      "Subject 5 has 288 trials\n",
      "Subject 6 has 288 trials\n",
      "Subject 7 has 288 trials\n",
      "Subject 8 has 288 trials\n"
     ]
    }
   ],
   "source": [
    "for subject_id in datasets.keys(): \n",
    "    print(f\"Subject {subject_id} has {len(datasets[subject_id])} trials\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject_id in datasets.keys(): \n",
    "    datasets[subject_id].return_subject_info = 'ftr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 240\n",
    "val_size = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG >>> Log name: \n",
      "\t20231214_task_BCICompet2a_batch_512_lr_0.002_Baseline\n",
      "1920 384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:459: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:1003.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/devuser/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: ./logs/BCICompet2a/2023-12-14_11-41-56-ftr_L1SO_0\n",
      "2023-12-14 11:41:56.618476: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-14 11:41:56.638458: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-14 11:41:56.946505: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "/home/devuser/.local/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py:256: Found unsupported keys in the lr scheduler dict: {'internal'}. HINT: remove them from the output of `configure_optimizers`.\n",
      "\n",
      "  | Name      | Type                   | Params\n",
      "-----------------------------------------------------\n",
      "0 | model     | ATTNConditionedSubjFtr | 34.0 K\n",
      "1 | criterion | CrossEntropyLoss       | 0     \n",
      "-----------------------------------------------------\n",
      "34.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "34.0 K    Total params\n",
      "0.136     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c1fa0948d6842e18fe219d034a4e715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devuser/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "/home/devuser/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "/home/devuser/.local/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Seed set to 42\n",
      "/home/devuser/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: ./logs/BCICompet2a/2023-12-14_11-44-32-ftr_L1SO_1\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name      | Type                   | Params\n",
      "-----------------------------------------------------\n",
      "0 | model     | ATTNConditionedSubjFtr | 34.0 K\n",
      "1 | criterion | CrossEntropyLoss       | 0     \n",
      "-----------------------------------------------------\n",
      "34.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "34.0 K    Total params\n",
      "0.136     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG >>> Log name: \n",
      "\t20231214_task_BCICompet2a_batch_512_lr_0.002_Baseline\n",
      "1920 384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3549b503ef7f44c7a07575897d80078b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: ./logs/BCICompet2a/2023-12-14_11-47-07-ftr_L1SO_2\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name      | Type                   | Params\n",
      "-----------------------------------------------------\n",
      "0 | model     | ATTNConditionedSubjFtr | 34.0 K\n",
      "1 | criterion | CrossEntropyLoss       | 0     \n",
      "-----------------------------------------------------\n",
      "34.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "34.0 K    Total params\n",
      "0.136     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG >>> Log name: \n",
      "\t20231214_task_BCICompet2a_batch_512_lr_0.002_Baseline\n",
      "1920 384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02756fea69ec4d94a4ee84de1ddfeae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: ./logs/BCICompet2a/2023-12-14_11-49-41-ftr_L1SO_3\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name      | Type                   | Params\n",
      "-----------------------------------------------------\n",
      "0 | model     | ATTNConditionedSubjFtr | 34.0 K\n",
      "1 | criterion | CrossEntropyLoss       | 0     \n",
      "-----------------------------------------------------\n",
      "34.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "34.0 K    Total params\n",
      "0.136     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG >>> Log name: \n",
      "\t20231214_task_BCICompet2a_batch_512_lr_0.002_Baseline\n",
      "1920 384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "774c69a6d82d4e33b2fe49057b48b5ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: ./logs/BCICompet2a/2023-12-14_11-52-16-ftr_L1SO_4\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name      | Type                   | Params\n",
      "-----------------------------------------------------\n",
      "0 | model     | ATTNConditionedSubjFtr | 34.0 K\n",
      "1 | criterion | CrossEntropyLoss       | 0     \n",
      "-----------------------------------------------------\n",
      "34.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "34.0 K    Total params\n",
      "0.136     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG >>> Log name: \n",
      "\t20231214_task_BCICompet2a_batch_512_lr_0.002_Baseline\n",
      "1920 384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ca28130cff84ea9ad7e1028d5de4148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: ./logs/BCICompet2a/2023-12-14_11-54-50-ftr_L1SO_5\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name      | Type                   | Params\n",
      "-----------------------------------------------------\n",
      "0 | model     | ATTNConditionedSubjFtr | 34.0 K\n",
      "1 | criterion | CrossEntropyLoss       | 0     \n",
      "-----------------------------------------------------\n",
      "34.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "34.0 K    Total params\n",
      "0.136     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG >>> Log name: \n",
      "\t20231214_task_BCICompet2a_batch_512_lr_0.002_Baseline\n",
      "1920 384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bacd5abd54d6463ab4064b94d95c56d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: ./logs/BCICompet2a/2023-12-14_11-57-22-ftr_L1SO_6\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name      | Type                   | Params\n",
      "-----------------------------------------------------\n",
      "0 | model     | ATTNConditionedSubjFtr | 34.0 K\n",
      "1 | criterion | CrossEntropyLoss       | 0     \n",
      "-----------------------------------------------------\n",
      "34.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "34.0 K    Total params\n",
      "0.136     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG >>> Log name: \n",
      "\t20231214_task_BCICompet2a_batch_512_lr_0.002_Baseline\n",
      "1920 384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0eb2ec91fe04372bca8c0f9c8fd8427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: ./logs/BCICompet2a/2023-12-14_11-59-53-ftr_L1SO_7\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name      | Type                   | Params\n",
      "-----------------------------------------------------\n",
      "0 | model     | ATTNConditionedSubjFtr | 34.0 K\n",
      "1 | criterion | CrossEntropyLoss       | 0     \n",
      "-----------------------------------------------------\n",
      "34.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "34.0 K    Total params\n",
      "0.136     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG >>> Log name: \n",
      "\t20231214_task_BCICompet2a_batch_512_lr_0.002_Baseline\n",
      "1920 384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2deff0c73a5b49319897b26f81940e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: ./logs/BCICompet2a/2023-12-14_12-02-24-ftr_L1SO_8\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name      | Type                   | Params\n",
      "-----------------------------------------------------\n",
      "0 | model     | ATTNConditionedSubjFtr | 34.0 K\n",
      "1 | criterion | CrossEntropyLoss       | 0     \n",
      "-----------------------------------------------------\n",
      "34.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "34.0 K    Total params\n",
      "0.136     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG >>> Log name: \n",
      "\t20231214_task_BCICompet2a_batch_512_lr_0.002_Baseline\n",
      "1920 384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cefdaf2628f457aa9d06b6bd79ec9d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n"
     ]
    }
   ],
   "source": [
    "for LOS in datasets.keys():\n",
    "    name = 'ftr_L1SO_'+str(LOS)\n",
    "    args.VERSION = f'{datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")}-{name}'\n",
    "\n",
    "\n",
    "    #### Set Log ####\n",
    "    args['current_time'] = datetime.now().strftime('%Y%m%d')\n",
    "    args['LOG_NAME'] = get_log_name(args)\n",
    "\n",
    "    #### Update configs ####\n",
    "    if args.downsampling != 0: args['sampling_rate'] = args.downsampling\n",
    "    seed_everything(args.SEED)\n",
    "\n",
    "\n",
    "    train_datasets = {}\n",
    "    val_datasets = {}\n",
    "    for subject_id in datasets.keys():\n",
    "        if subject_id != LOS:\n",
    "            train_datasets[subject_id] = torch.utils.data.Subset(datasets[subject_id], range(train_size))\n",
    "            val_datasets[subject_id] = torch.utils.data.Subset(datasets[subject_id], range(train_size, train_size+val_size))\n",
    "\n",
    "\n",
    "    train_dataset_all = torch.utils.data.ConcatDataset(list(train_datasets.values()))\n",
    "    val_dataset_all = torch.utils.data.ConcatDataset(list(val_datasets.values()))\n",
    "    print(len(train_dataset_all), len(val_dataset_all))\n",
    "\n",
    "    train_dataloader_all = DataLoader(train_dataset_all, batch_size=args['batch_size'], shuffle=True, num_workers=0, persistent_workers=False)\n",
    "    val_dataloader_all = DataLoader(val_dataset_all, batch_size=args['batch_size'], shuffle=False, num_workers=0, persistent_workers=False)\n",
    "\n",
    "\n",
    "    model = ATTNConditionedSubjFtr(args, eeg_normalization = 'LayerNorm', subject_normalization='LayerNorm',  embedding_dimension=23, combined_features_dimension=43, num_classes=args['num_classes'] )\n",
    "    lit_model = LitModel(args, model)\n",
    "\n",
    "    logger = TensorBoardLogger(args.LOG_PATH, \n",
    "                                    name=args.VERSION)\n",
    "\n",
    "    callbacks = get_callbacks(monitor='val_loss', args=args)\n",
    "\n",
    "\n",
    "    trainer = Trainer(\n",
    "            max_epochs=args['EPOCHS'],\n",
    "            callbacks=callbacks,\n",
    "            default_root_dir=args.CKPT_PATH,\n",
    "            logger=logger,\n",
    "            enable_progress_bar=False\n",
    "        )\n",
    "\n",
    "    trainer.fit(lit_model,\n",
    "            train_dataloaders=train_dataloader_all,\n",
    "            val_dataloaders=val_dataloader_all)\n",
    "        \n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
