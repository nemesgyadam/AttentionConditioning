{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, yaml\n",
    "from datetime import datetime\n",
    "from easydict import EasyDict\n",
    "from glob import glob\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataloader.bci_compet import get_dataset\n",
    "from dataloader.bci_compet import BCICompet2aIV\n",
    "\n",
    "from model.litmodel import LitModel\n",
    "from model.litmodel import get_litmodel\n",
    "from model.cat_conditioned import CatConditioned\n",
    "from model.attn_conditioned import ATTNConditioned\n",
    "from model.attn_conditioned_subj_avg import ATTNConditionedSubjAvg\n",
    "from model.attn_conditioned_subj_ftr import ATTNConditionedSubjFtr\n",
    "\n",
    "\n",
    "\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set confings\n",
    "config_name = 'bcicompet2a_config'\n",
    "with open(f'configs/{config_name}.yaml') as file:\n",
    "    config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    args = EasyDict(config)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "#### Set Device ####\n",
    "if torch.cuda.is_available():\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = args.GPU_NUM\n",
    "cudnn.benchmark = True\n",
    "cudnn.fastest = True\n",
    "cudnn.deterministic = True\n",
    "\n",
    "#### Set SEED ####\n",
    "seed_everything(args.SEED)\n",
    "\n",
    "#### Update configs ####\n",
    "if args.downsampling != 0: args['sampling_rate'] = args.downsampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cache\n"
     ]
    }
   ],
   "source": [
    "CACHE_ROOT = 'cache'\n",
    "TEST_ROOT = 'test_results'\n",
    "\n",
    "args.is_test = True\n",
    "\n",
    "def load_dataset(args, return_subject_id=False):\n",
    "    datasets = {}\n",
    "    for subject_id in range(0,9):\n",
    "        args['target_subject'] = subject_id\n",
    "        datasets[subject_id] = BCICompet2aIV(args)\n",
    "    return datasets\n",
    "\n",
    "path = os.path.join(CACHE_ROOT, f'{config_name}_base_test.pkl')\n",
    "\n",
    "if not os.path.isfile(path):\n",
    "    print('Cache miss, generating cache')\n",
    "    datasets = load_dataset(args)\n",
    "    with open(path, 'wb') as file:\n",
    "        pickle.dump(datasets, file)\n",
    "else:\n",
    "    print('Loading cache')\n",
    "    with open(path, 'rb') as file:\n",
    "        datasets = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoints/BCICompet2a/2023-11-30_15-04-02-all_attn_cond_ftr/epoch=481-val_loss=0.875.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e0203d0a85143c28535b3d8d944ccad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a9c3221a3f44ca90fc6514e64db5e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "def75e0290c2426188daad1b4fdf9fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27482cbb86e14d0ebe9371931cba1a63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37dab97335e447648b3c758bba538d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8034ce305574d83ba86affc5fe2b69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f407da5eb284eca91e35309d5e41bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e24c9fee9b4b769fe79ba8adbbde90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96519b472a944b358fbf3115542a4353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# version = '2023-11-30_14-52-13-all_baseline'\n",
    "# subj_info = ''\n",
    "\n",
    "# version = '2023-11-30_14-47-59-all_cat_cond'\n",
    "# subj_info = 'id'\n",
    "\n",
    "# version = '2023-11-30_14-55-16-all_attn_cond'\n",
    "# subj_info = 'id'\n",
    "\n",
    "# version = '2023-11-30_14-59-13-all_attn_cond_avg'\n",
    "# subj_info = 'avg'\n",
    "\n",
    "version = '2023-11-30_15-04-02-all_attn_cond_ftr'\n",
    "subj_info = 'ftr'\n",
    "\n",
    "ckpt_path = sorted(glob(f'{args.CKPT_PATH}/{args.task}/{version}/*.ckpt'))[-1]\n",
    "print(ckpt_path)\n",
    "\n",
    "#model = get_litmodel(args)\n",
    "#in_model = CatConditioned(args, n_subjects=9, subject_filters=16, final_features=4, n_classes=args['num_classes'] )\n",
    "#in_model = ATTNConditioned(args, n_subjects=9, embed_dim=16,  n_classes=args['num_classes'] )\n",
    "#in_model =  ATTNConditionedSubjAvg(args, n_subjects=9, embed_dim=16,  n_classes=args['num_classes'] )\n",
    "in_model = ATTNConditionedSubjFtr(args, n_subjects=9, embed_dim=16,  n_classes=args['num_classes'] )\n",
    "model = LitModel(args, in_model)\n",
    "model.load_state_dict(torch.load(ckpt_path)['state_dict'], strict=False)\n",
    "trainer = Trainer()          \n",
    "        \n",
    "result_dict = {}\n",
    "\n",
    "for subject_id in range(0,9):\n",
    "    datasets[subject_id].return_subject_info = subj_info\n",
    "    test_dataloader = DataLoader(datasets[subject_id],\n",
    "                                    batch_size=args.batch_size,\n",
    "                                    pin_memory=False,\n",
    "                                    num_workers=args.num_workers)\n",
    "    gt = datasets[0].label                                   \n",
    "    logits = trainer.predict(model, dataloaders=test_dataloader)\n",
    "    pred = torch.cat(logits, dim=0).argmax(axis=1).detach().cpu().numpy()\n",
    "    acc = accuracy_score(pred, gt)\n",
    "    kappa = cohen_kappa_score(pred, gt)\n",
    "    result_dict[subject_id] = {'acc': acc, 'kappa': kappa}\n",
    "result_df = pd.DataFrame(result_dict).T\n",
    "\n",
    "result_df.to_csv(f'{TEST_ROOT}/{args.task}/{version}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[[-0.88996919, -1.27907056, -1.35011277, ...,  0.28252727,\n",
       "           0.28288531,  0.16730833],\n",
       "         [-0.96760044, -1.0159445 , -0.87678273, ...,  0.85993223,\n",
       "           1.03264032,  0.93162256],\n",
       "         [-0.6876539 , -0.89942583, -0.90780913, ...,  0.90229599,\n",
       "           1.0303905 ,  0.93598802],\n",
       "         ...,\n",
       "         [-1.59265782, -1.45238073, -1.1846601 , ...,  1.03645961,\n",
       "           1.32855268,  1.38238639],\n",
       "         [-1.58725833, -1.51257941, -1.2675144 , ...,  0.86497084,\n",
       "           1.16638995,  1.22026448],\n",
       "         [-1.3676114 , -1.14787983, -1.01731697, ...,  0.79437571,\n",
       "           1.11341729,  1.22393781]]]),\n",
       " 'subject_info': 0,\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6878858024691358, 0.5838477366255144)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['acc'].mean(), result_df['kappa'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
