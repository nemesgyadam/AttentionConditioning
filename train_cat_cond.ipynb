{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Code\\m-shallowconvnet\\.venv\\lib\\site-packages\\braindecode\\datautil\\preprocess.py:10: UserWarning: datautil.preprocess module is deprecated and is now under preprocessing.preprocess, please use from import braindecode.preprocessing.preprocess\n",
      "  warn('datautil.preprocess module is deprecated and is now under '\n"
     ]
    }
   ],
   "source": [
    "import os, yaml\n",
    "from easydict import EasyDict\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from dataloader.bci_compet import get_dataset\n",
    "from dataloader.bci_compet import BCICompet2aIV\n",
    "\n",
    "from model.litmodel import LitModel\n",
    "from model.cat_conditioned import CatConditioned\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "\n",
    "\n",
    "from utils.setup_utils import (\n",
    "    get_device,\n",
    "    get_log_name,\n",
    ")\n",
    "from utils.training_utils import get_callbacks\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG >>> Log name: \n",
      "\t20231127_task_BCICompet2a_batch_64_lr_2e-3_Baseline\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_name = 'bcicompet2a_config'\n",
    "\n",
    "with open(f'configs/{config_name}.yaml') as file:\n",
    "    config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    args = EasyDict(config)\n",
    "\n",
    "\n",
    "#### Set Log ####\n",
    "args['current_time'] = datetime.now().strftime('%Y%m%d')\n",
    "args['LOG_NAME'] = get_log_name(args)\n",
    "\n",
    "#### Update configs ####\n",
    "args.lr = float(args.lr)\n",
    "if args.downsampling != 0: args['sampling_rate'] = args.downsampling\n",
    "\n",
    "seed_everything(args.SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG >>> Filename: Datasets/BCI_Competition_IV_2a\\A01T.gdf\n",
      "Extracting EDF parameters from c:\\Code\\m-shallowconvnet\\Datasets\\BCI_Competition_IV_2a\\A01T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 672527  =      0.000 ...  2690.108 secs...\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up low-pass filter at 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal lowpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 87 samples (0.348 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 751 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  4.89it/s]\n"
     ]
    }
   ],
   "source": [
    "datasets = {}\n",
    "for subject_id in range(0,1):\n",
    "    args['target_subject'] = subject_id\n",
    "    datasets[subject_id] = BCICompet2aIV(args, return_subject_id=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 0 has 288 trials\n"
     ]
    }
   ],
   "source": [
    "for subject_id in datasets.keys(): \n",
    "    print(f\"Subject {subject_id} has {len(datasets[subject_id])} trials\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 48)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = 240\n",
    "val_size = 48\n",
    "\n",
    "\n",
    "train_datasets = {}\n",
    "val_datasets = {}\n",
    "for subject_id in datasets.keys():\n",
    "    train_datasets[subject_id] = torch.utils.data.Subset(datasets[subject_id], range(train_size))\n",
    "    val_datasets[subject_id] = torch.utils.data.Subset(datasets[subject_id], range(train_size, train_size+val_size))\n",
    "\n",
    "\n",
    "train_dataset_all = torch.utils.data.ConcatDataset(list(train_datasets.values()))\n",
    "val_dataset_all = torch.utils.data.ConcatDataset(list(val_datasets.values()))\n",
    "len(train_dataset_all), len(val_dataset_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader_all = DataLoader(train_dataset_all, batch_size=32, shuffle=True)\n",
    "val_dataloader_all = DataLoader(val_dataset_all, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject_filters eeg_dim\n",
      "16 744\n"
     ]
    }
   ],
   "source": [
    "model = CatConditioned(args, n_subjects=9, subject_filters=16, final_features=4, n_classes=args['num_classes'] )\n",
    "lit_model = LitModel(args, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "torch.Size([1, 1, 22, 751]) torch.Size([1])\n",
      "torch.float64 torch.int32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "eeg_input = torch.from_numpy(np.array([train_dataset_all[0]['data']]))\n",
    "subject_id =  torch.from_numpy(np.array([train_dataset_all[0]['subject_id']]))\n",
    "print(type(eeg_input), type(subject_id))\n",
    "print(eeg_input.shape, subject_id.shape)\n",
    "print(eeg_input.dtype, subject_id.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eeg_features subject_features\n",
      "torch.Size([1, 744]) torch.Size([1, 16])\n",
      "torch.Size([1, 760])\n",
      "Linear(in_features=760, out_features=4, bias=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1679, -1.4003, -0.3376, -0.1858]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(eeg_input, subject_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(args.LOG_PATH, \n",
    "                                    name='my_train_sub0_cat_cond')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = get_callbacks(monitor='val_loss', args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "            max_epochs=250,\n",
    "            callbacks=callbacks,\n",
    "            default_root_dir=args.CKPT_PATH,\n",
    "            logger=logger,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model     | CatConditioned   | 30.4 K\n",
      "1 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "30.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "30.4 K    Total params\n",
      "0.122     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 8/8 [02:23<00:00,  0.06it/s, v_num=5, val_loss=1.400, val_acc=0.292, train_loss=1.440, train_acc=0.304]\n",
      "Epoch 249: 100%|██████████| 8/8 [00:00<00:00, 12.04it/s, v_num=5, val_loss=0.817, val_acc=0.771, train_loss=0.626, train_acc=0.846]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 8/8 [00:00<00:00, 11.92it/s, v_num=5, val_loss=0.817, val_acc=0.771, train_loss=0.626, train_acc=0.846]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(lit_model,\n",
    "            train_dataloaders=train_dataloader_all,\n",
    "            val_dataloaders=val_dataloader_all)\n",
    "        \n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
